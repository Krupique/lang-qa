{
    "llm": "NousResearch/Llama-2-7b-chat-hf",

    "BitsAndBytesConfig": {
        "use_4bit": true,
        "bnb_4bit_compute_dtype": "float16",
        "bnb_4bit_quant_type": "nf4",
        "use_nested_quant": false
    },

    "LoraConfig": {
        "r": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "bias": "none",
        "task_type": "CAUSAL_LM"
    },

    "TrainingArguments": {
        "per_device_train_batch_size": 1,
        "gradient_accumulation_steps": 4,
        "optim": "paged_adamw_32bit",
        "learning_rate": 2e-4,
        "lr_scheduler_type": "cosine",
        "save_strategy": "epoch",
        "logging_steps": 10,
        "num_train_epochs": 3,
        "max_steps": 150,
        "fp16": true
    }
}